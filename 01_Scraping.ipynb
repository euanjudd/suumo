{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c888f424-8a66-4fa8-84b1-4827a22313d6",
   "metadata": {},
   "source": [
    "Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57d81e-a3fa-4660-9e92-a80bea2e2a19",
   "metadata": {},
   "source": [
    "# Scrape SUUMO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbb1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retry import retry # automatic retry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup # parse HTML\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d26645",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=10, backoff=2)\n",
    "def get_html(url):\n",
    "    \"\"\"\n",
    "    Uses BeautifulSoup to parse HTML content from url. Retries 3 times with 10 second delay that doubles each try.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Will raise an exception for HTTP errors\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    except requests.RequestException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83757e6",
   "metadata": {},
   "source": [
    "## 1. Scrape URLs\n",
    "- Scrape URLs for individual purchasable property from SUUMO.jp collection pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104eea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/app/data/used_property_urls.csv\"):\n",
    "    \n",
    "    collection_pages = {\n",
    "        \"used_apartments\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=011&sc=13101&sc=13102&sc=13103&sc=13104&sc=13105&sc=13106&sc=13107&sc=13108&sc=13109&sc=13110&sc=13111&sc=13112&sc=13113&sc=13114&sc=13115&sc=13116&sc=13117&sc=13118&sc=13119&sc=13120&sc=13121&sc=13122&sc=13123&ta=13&po=0&pj=1&pc=100\",\n",
    "        # \"new_apartments\": \"https://suumo.jp/jj/bukken/ichiran/JJ011FC001/?ar=030&bs=010&ta=13&po=0&pj=1&initFlg=1&bknlistmodeflg=1&page=1&pc=100\",\n",
    "        \"used_houses\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=021&cn=9999999&cnb=0&ekTjCd=&ekTjNm=&hb=0&ht=9999999&kb=1&kt=9999999&sc=13101&sc=13102&sc=13103&sc=13104&sc=13105&sc=13113&sc=13106&sc=13107&sc=13108&sc=13118&sc=13121&sc=13122&sc=13123&sc=13109&sc=13110&sc=13111&sc=13112&sc=13114&sc=13115&sc=13120&sc=13116&sc=13117&sc=13119&ta=13&tb=0&tj=0&tt=9999999&po=0&pj=1&pc=100\",\n",
    "        # \"new_houses\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=020&ekTjCd=&ekTjNm=&hb=0&ht=9999999&kb=1&km=1&kt=9999999&kw=1&sc=13102&sc=13103&sc=13104&sc=13105&sc=13113&sc=13106&sc=13107&sc=13108&sc=13118&sc=13121&sc=13122&sc=13123&sc=13109&sc=13110&sc=13111&sc=13112&sc=13114&sc=13115&sc=13120&sc=13116&sc=13117&sc=13119&ta=13&tb=0&tj=0&tt=9999999&po=0&pj=1&pc=100\"\n",
    "    }\n",
    "\n",
    "    list_urls = []\n",
    "    page = 0\n",
    "\n",
    "    for category, url in collection_pages.items():\n",
    "        print(f\"Category: {category}\")\n",
    "\n",
    "        while True:\n",
    "            soup = get_html(url.format(page))\n",
    "            \n",
    "            if not soup:\n",
    "                print(f\"No soup in {url}\")\n",
    "                break \n",
    "\n",
    "            for h2 in soup.find_all('h2', class_='property_unit-title'):\n",
    "                a_tag = h2.find('a', href=True) \n",
    "                if a_tag and a_tag['href']:\n",
    "                    property_url = \"https://suumo.jp\" + a_tag['href']\n",
    "                    list_urls.append((category, property_url))\n",
    "\n",
    "            # Find the 'next' page link with text \"次へ\"\n",
    "            next_page = soup.find('a', text=\"次へ\")\n",
    "            if next_page and next_page.get('href'):\n",
    "                url = \"https://suumo.jp\" + next_page['href']\n",
    "            else:\n",
    "                print(f\"No more {category} pages.\")\n",
    "                break\n",
    "\n",
    "    df_urls = pd.DataFrame(list_urls, columns=['Category', 'URL'])\n",
    "    df_urls.to_csv(\"/app/data/used_property_urls.csv\", index=False)\n",
    "    df_urls.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a65362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_75070928/\n",
      "https://suumo.jp/ms/chuko/tokyo/sc_taito/nc_75117331/\n",
      "Processed 2/25349 URLs\n"
     ]
    }
   ],
   "source": [
    "def parse_price(value):\n",
    "    try:\n",
    "        total_price = 0\n",
    "        price_str = value.strip().split('円')[0]\n",
    "        if \"億\" in price_str:\n",
    "            oku_pattern = re.compile(r'(\\d+)億')       # match int number before '億'\n",
    "            oku_match = oku_pattern.search(price_str)\n",
    "            if oku_match:\n",
    "                total_price += int(oku_match.group(1)) * 100000000\n",
    "        if \"万\" in price_str:\n",
    "            man_pattern = re.compile(r'(\\d+)万')\n",
    "            man_match = man_pattern.search(price_str)\n",
    "            if man_match:\n",
    "                total_price += int(man_match.group(1)) * 10000\n",
    "            return total_price\n",
    "        else:\n",
    "            return int(price_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def parse_area(value):\n",
    "    try:\n",
    "        area_pattern = re.compile(r'(\\d+(\\.\\d+)?)m')   # match decimal number before 'm'\n",
    "        area_match = area_pattern.search(value)\n",
    "        if area_match:\n",
    "            return float(area_match.group(1))\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def extract_number(string):\n",
    "    match = re.search(r'\\d+', string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "def parse_year(value):\n",
    "    try:\n",
    "        return int(value.strip().split('年')[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    \"\"\" Remove white space characters suchs as newline, tab, etc. \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def parse_features(soup):\n",
    "    \"\"\" Get soup of data in the 特徴ピックアップ section. \"\"\"\n",
    "    features_section = soup.find('h3', string='特徴ピックアップ')\n",
    "    if features_section:\n",
    "        parent_div = features_section.find_parent('div', class_='secTitleOuterR')\n",
    "        if parent_div == None:\n",
    "            parent_div = features_section.find_parent('div', class_='secTitleOuterK')\n",
    "        features_div = parent_div.find_next_sibling('div', class_='mt10')\n",
    "        if features_div:\n",
    "            features_text = ' '.join(features_div.stripped_strings)\n",
    "            return remove_whitespace(features_text)\n",
    "    return None\n",
    "\n",
    "pd_urls = pd.read_csv(\"/app/data/used_property_urls.csv\", index_col=False)\n",
    "df_urls = pd.DataFrame(pd_urls, columns=['Category', 'URL'])\n",
    "df_apt_urls = df_urls.loc[df_urls['Category'] == 'used_apartments']\n",
    "\n",
    "list_data = []\n",
    "\n",
    "count = 0\n",
    "total = len(df_urls)\n",
    "batch_size = 1000\n",
    "\n",
    "list_data = []\n",
    "\n",
    "if os.path.exists(\"/app/data/used_property_data.csv\"):\n",
    "    df_partial = pd.read_csv(f\"/app/data/used_property_data.csv\", index_col=False)\n",
    "    # Extract URL sets\n",
    "    urls_set1 = set(df_apt_urls['URL'])\n",
    "    urls_set2 = set(df_partial['URL'])\n",
    "    # URLs in df_apt_urls but not in df_partial\n",
    "    unique_urls1 = list(urls_set1 - urls_set2)\n",
    "else:\n",
    "    unique_urls1 = list(df_apt_urls['URL'])\n",
    "\n",
    "for url in unique_urls1:\n",
    "    print(url)\n",
    "    soup = get_html(url)\n",
    "\n",
    "    if not soup:\n",
    "        print(f\"No soup in {url}\")\n",
    "        break \n",
    "\n",
    "    # Initialize dictionary to store the data\n",
    "    property_data = {}\n",
    "    property_data['url'] = url\n",
    "\n",
    "    # Iterate over each row in the table\n",
    "    target_table = soup.find('table', summary=\"表\")\n",
    "    for row in target_table.find_all('tr'):\n",
    "        # Find all th and td pairs in the row\n",
    "        ths = row.find_all('th')\n",
    "        tds = row.find_all('td')\n",
    "        \n",
    "        for th, td in zip(ths, tds):\n",
    "            header = th.text.strip()\n",
    "            value = td.text.strip()\n",
    "\n",
    "            if \"価格\" in header:\n",
    "                property_data['price'] = parse_price(value)\n",
    "            elif \"間取り\" in header:\n",
    "                property_data['plan'] = value.strip()\n",
    "            elif \"専有面積\" in header:\n",
    "                property_data['area'] = parse_area(value)\n",
    "            elif \"その他面積\" in header:\n",
    "                property_data['balcony_area'] = parse_area(value)\n",
    "            elif \"所在階/構造・階建\" in header:\n",
    "                level_details = value.strip().split('/')\n",
    "                property_data['level'] = extract_number(level_details[0])\n",
    "                property_data['no_floors'] = extract_number(level_details[1])\n",
    "            elif \"完成時期（築年月）\" in header:\n",
    "                property_data['year'] = parse_year(value)\n",
    "            elif \"住所\" in header:\n",
    "                property_data['address'] = value.strip().split('\\n')[0]\n",
    "\n",
    "    property_data['features'] = parse_features(soup)\n",
    "\n",
    "    if any(value is None for value in property_data.values()):\n",
    "        print(f\"{url} data has None.\")\n",
    "        print(property_data)\n",
    "        break\n",
    "\n",
    "    list_data.append(property_data)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # Periodically save property_data and clear the list from memory\n",
    "    if count % batch_size == 0:\n",
    "        print(f\"Processed {count}/{total} URLs\")\n",
    "        df_data = pd.DataFrame(list_data)\n",
    "        df_merged = pd.merge(df_apt_urls, df_data, left_on='URL', right_on='url', how='inner')\n",
    "        df_merged = df_merged.drop(columns=['url'])\n",
    "\n",
    "        if not os.path.exists(\"/app/data/used_property_data.csv\"):\n",
    "            # First batch: Write header and data\n",
    "            df_merged.to_csv(f'/app/data/used_property_data.csv', index=False)\n",
    "        else:\n",
    "            df_merged.to_csv(f'/app/data/used_property_data.csv', mode='a', header=False, index=False)\n",
    "\n",
    "        property_data.clear()\n",
    "        list_data = []\n",
    "        gc.collect()  # Manually release memory\n",
    "        time.sleep(5)  # Rest 5 seconds to reduce server load\n",
    "\n",
    "        break\n",
    "\n",
    "# df_merged = pd.read_csv(f\"/app/data/used_property_data.csv\", index_col=False)\n",
    "# df_merged.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594618f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>URL</th>\n",
       "      <th>price</th>\n",
       "      <th>plan</th>\n",
       "      <th>area</th>\n",
       "      <th>balcony_area</th>\n",
       "      <th>level</th>\n",
       "      <th>no_floors</th>\n",
       "      <th>year</th>\n",
       "      <th>address</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>used_apartments</td>\n",
       "      <td>https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...</td>\n",
       "      <td>11900000</td>\n",
       "      <td>2DK</td>\n",
       "      <td>41.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1979</td>\n",
       "      <td>東京都足立区花畑５-2-9</td>\n",
       "      <td>年内引渡可 / 即引渡可 / 角住戸 / 陽当り良好 / 全居室収納 / シャワー付洗面化粧...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>used_apartments</td>\n",
       "      <td>https://suumo.jp/ms/chuko/tokyo/sc_taito/nc_75...</td>\n",
       "      <td>13800000</td>\n",
       "      <td>1K</td>\n",
       "      <td>16.45</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1991</td>\n",
       "      <td>東京都台東区松が谷３-６－２</td>\n",
       "      <td>瑕疵保証付（不動産会社独自） / ２沿線以上利用可 / 内装リフォーム / 駅まで平坦 / ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Category                                                URL  \\\n",
       "0  used_apartments  https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...   \n",
       "1  used_apartments  https://suumo.jp/ms/chuko/tokyo/sc_taito/nc_75...   \n",
       "\n",
       "      price plan   area  balcony_area  level  no_floors  year         address  \\\n",
       "0  11900000  2DK  41.34          2.43      2          4  1979   東京都足立区花畑５-2-9   \n",
       "1  13800000   1K  16.45          2.69      5          9  1991  東京都台東区松が谷３-６－２   \n",
       "\n",
       "                                            features  \n",
       "0  年内引渡可 / 即引渡可 / 角住戸 / 陽当り良好 / 全居室収納 / シャワー付洗面化粧...  \n",
       "1  瑕疵保証付（不動産会社独自） / ２沿線以上利用可 / 内装リフォーム / 駅まで平坦 / ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be8d8c",
   "metadata": {},
   "source": [
    "ADD BALCONY AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_property_data(url):\n",
    "    \n",
    "\n",
    "# pd_urls = pd.read_csv(\"/app/data/property_urls.csv\", index_col=False)\n",
    "# df_urls = pd.DataFrame(pd_urls, columns=['Category', 'URL'])\n",
    "# df_urls.head()\n",
    "\n",
    "# property_data = []\n",
    "\n",
    "# count = 0\n",
    "# total = len(df_urls)\n",
    "# batch_size = 1000\n",
    "\n",
    "# for url in df_urls['URL']:\n",
    "#     soup = get_html(url)\n",
    "\n",
    "#     if not soup:\n",
    "#         print(f\"No soup in {url}\")\n",
    "#         property_data.append({'URL': url, \n",
    "#                         '向き': \"掲載終了\", \n",
    "#                         '間取り詳細': \"掲載終了\", \n",
    "#                         '物件の構造': \"掲載終了\", \n",
    "#                         '物件の階建': \"掲載終了\",\n",
    "#                         '築年月': \"掲載終了\", \n",
    "#                         '損保': \"掲載終了\", \n",
    "#                         '駐車場': \"掲載終了\", \n",
    "#                         '取引態様': \"掲載終了\",\n",
    "#                         '条件': \"掲載終了\", \n",
    "#                         '総戸数': \"掲載終了\", \n",
    "#                         '契約期間': \"掲載終了\", \n",
    "#                         '仲介手数料': \"掲載終了\",\n",
    "#                         '保証会社': \"掲載終了\", \n",
    "#                         '備考': \"掲載終了\", \n",
    "#                         '部屋の特徴': \"掲載終了\"})\n",
    "#         break \n",
    "\n",
    "#     # Find the \"Direction\"\n",
    "#     try:\n",
    "#         element = soup.find(\"table\", {\"class\": \"property_view_table\"})\n",
    "#         direction = element.find('th', string=\"向き\").find_next_sibling('td').get_text(strip=True)\n",
    "#     except AttributeError:\n",
    "#         direction = 'Null'\n",
    "    \n",
    "#     # Find the required data table\n",
    "#     tbodys = soup.find(\"table\", {\"class\": \"data_table table_gaiyou\"})\n",
    "    \n",
    "#     # Define a function to safely fetch the data for each field\n",
    "#     def get_text_safe(th_string):\n",
    "#         try:\n",
    "#             return tbodys.find('th', string=th_string).find_next_sibling('td').get_text(strip=True)\n",
    "#         except AttributeError:\n",
    "#             return 'Null'\n",
    "    \n",
    "#     # Use the function to fetch data for each field\n",
    "#     layout_detail = get_text_safe('間取り詳細')\n",
    "#     structure = get_text_safe('構造')\n",
    "#     floor = get_text_safe('階建')\n",
    "#     yearmonth = get_text_safe('築年月')\n",
    "#     insurance = get_text_safe('損保')\n",
    "#     parking = get_text_safe('駐車場')\n",
    "#     transaction_type = get_text_safe('取引態様')\n",
    "#     conditions = get_text_safe('条件')\n",
    "#     total_units = get_text_safe('総戸数')\n",
    "#     lease_term = get_text_safe('契約期間')\n",
    "#     intermediary_fee = get_text_safe('仲介手数料')\n",
    "#     guarantee_company = get_text_safe('保証会社')\n",
    "#     note = get_text_safe('備考')\n",
    "\n",
    "#     # Find room features\n",
    "#     try:\n",
    "#         li_element = soup.find('div', {'id': 'bkdt-option'}).find('li')\n",
    "#         feature = li_element.get_text(strip=True)\n",
    "#     except AttributeError:\n",
    "#         feature = 'Null'\n",
    "\n",
    "#     # Append the data to the list\n",
    "#     property_data.append({\n",
    "#         'URL': url,\n",
    "#         '向き': direction,\n",
    "#         '間取り詳細': layout_detail,\n",
    "#         '物件の構造': structure,\n",
    "#         '物件の階建': floor,\n",
    "#         '築年月': yearmonth,\n",
    "#         '損保': insurance,\n",
    "#         '駐車場': parking,\n",
    "#         '取引態様': transaction_type,\n",
    "#         '条件': conditions,\n",
    "#         '総戸数': total_units,\n",
    "#         '契約期間': lease_term,\n",
    "#         '仲介手数料': intermediary_fee,\n",
    "#         '保証会社': guarantee_company,\n",
    "#         '備考': note,\n",
    "#         '部屋の特徴': feature\n",
    "#     })\n",
    "    \n",
    "#     # Update the counter and print the current progress\n",
    "#     count += 1\n",
    "#     print(f\"Processed {count}/{total} URLs\")\n",
    "\n",
    "#     # Periodically save property_data and clear the list from memory\n",
    "#     if count % batch_size == 0:\n",
    "#         partial_df = pd.DataFrame(property_data)\n",
    "#         partial_df.to_csv(f'property_data_part_{count // batch_size}.csv', index=False)\n",
    "#         property_data.clear()\n",
    "#         gc.collect()  # Manually release memory\n",
    "#         time.sleep(5)  # Rest 5 seconds to reduce server load\n",
    "#     partial_df = pd.DataFrame(property_data)\n",
    "#     partial_df.head()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce383fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>向き</th>\n",
       "      <th>間取り詳細</th>\n",
       "      <th>物件の構造</th>\n",
       "      <th>物件の階建</th>\n",
       "      <th>築年月</th>\n",
       "      <th>損保</th>\n",
       "      <th>駐車場</th>\n",
       "      <th>取引態様</th>\n",
       "      <th>条件</th>\n",
       "      <th>総戸数</th>\n",
       "      <th>契約期間</th>\n",
       "      <th>仲介手数料</th>\n",
       "      <th>保証会社</th>\n",
       "      <th>備考</th>\n",
       "      <th>部屋の特徴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL    向き 間取り詳細 物件の構造 物件の階建  \\\n",
       "0  https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...  Null  Null  Null  Null   \n",
       "\n",
       "    築年月    損保   駐車場  取引態様    条件   総戸数  契約期間 仲介手数料  保証会社    備考 部屋の特徴  \n",
       "0  Null  Null  Null  Null  Null  Null  Null  Null  Null  Null  Null  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b2819-d8b7-4728-957e-fe1a4cde0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for page in range(1, max_page + 1):\n",
    "#     url = base_url.format(page) # Replace {} with page number\n",
    "#     soup = get_html(url)        # Get parsed data\n",
    "\n",
    "#     property_tags = soup.findAll(\"div\", {\"class\": \"cassetteitem\"})  # All <div>'s with \"cassetteitem\" in the class attribute contain propetry info.\n",
    "    \n",
    "#     # print(f\"Page: {page} - items: {property_tags}\")\n",
    "    \n",
    "#     for property_tag in property_tags:\n",
    "#         stations = property_tag.findAll(\"div\", {\"class\": \"cassetteitem_detail-text\"})\n",
    "        \n",
    "#         # process each station\n",
    "#         for station in stations:\n",
    "#             # define variable \n",
    "#             base_data = {}\n",
    "\n",
    "#             # collect base information    \n",
    "#             # Name\n",
    "#             base_data[\"名称\"] = property_tag.find(\"div\", {\"class\": \"cassetteitem_content-title\"}).getText().strip()\n",
    "            \n",
    "#             # category\n",
    "#             base_data[\"カテゴリー\"] = property_tag.find(\"div\", {\"class\": \"cassetteitem_content-label\"}).getText().strip()\n",
    "\n",
    "#             # address\n",
    "#             base_data[\"アドレス\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col1\"}).getText().strip()\n",
    "\n",
    "#             # nearby station\n",
    "#             base_data[\"アクセス\"] = station.getText().strip()\n",
    "\n",
    "#             # building's age\n",
    "#             base_data[\"築年数\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col3\"}).findAll(\"div\")[0].getText().strip()\n",
    "\n",
    "#             # structure\n",
    "#             base_data[\"構造\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col3\"}).findAll(\"div\")[1].getText().strip()\n",
    "            \n",
    "#             # process data for each room\n",
    "#             tbodys = property_tag.find(\"table\", {\"class\": \"cassetteitem_other\"}).findAll(\"tbody\")\n",
    "            \n",
    "#             for tbody in tbodys:\n",
    "#                 data = base_data.copy()\n",
    "\n",
    "#                 # floor\n",
    "#                 data[\"階数\"] = tbody.findAll(\"td\")[2].getText().strip()\n",
    "\n",
    "#                 # rent\n",
    "#                 data[\"家賃\"] = tbody.findAll(\"td\")[3].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 # Management fee\n",
    "#                 data[\"管理費\"] = tbody.findAll(\"td\")[3].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 # deposit\n",
    "#                 data[\"敷金\"] = tbody.findAll(\"td\")[4].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 #gratuity fee\n",
    "#                 data[\"礼金\"] = tbody.findAll(\"td\")[4].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 #layout\n",
    "#                 data[\"間取り\"] = tbody.findAll(\"td\")[5].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 #area(m^2)\n",
    "#                 data[\"面積\"] = tbody.findAll(\"td\")[5].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 data[\"URL\"] = \"https://suumo.jp\" + tbody.findAll(\"td\")[8].find(\"a\").get(\"href\")\n",
    "                \n",
    "#                 all_data.append(data)\n",
    "# df = pd.DataFrame(all_data)\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
