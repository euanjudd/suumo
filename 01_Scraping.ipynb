{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c888f424-8a66-4fa8-84b1-4827a22313d6",
   "metadata": {},
   "source": [
    "Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57d81e-a3fa-4660-9e92-a80bea2e2a19",
   "metadata": {},
   "source": [
    "# Scrape SUUMO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbb1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retry import retry # automatic retry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup # parse HTML\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d26645",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=10, backoff=2)\n",
    "def get_html(url):\n",
    "    \"\"\"\n",
    "    Uses BeautifulSoup to parse HTML content from url. Retries 3 times with 10 second delay that doubles each try.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Will raise an exception for HTTP errors\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    except requests.RequestException:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83757e6",
   "metadata": {},
   "source": [
    "## 1. Scrape URLs\n",
    "- Scrape URLs for individual purchasable property from SUUMO.jp collection pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104eea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/app/data/property_urls.csv\"):\n",
    "    \n",
    "    collection_pages = {\n",
    "        \"used_apartments\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=011&sc=13101&sc=13102&sc=13103&sc=13104&sc=13105&sc=13106&sc=13107&sc=13108&sc=13109&sc=13110&sc=13111&sc=13112&sc=13113&sc=13114&sc=13115&sc=13116&sc=13117&sc=13118&sc=13119&sc=13120&sc=13121&sc=13122&sc=13123&ta=13&po=0&pj=1&pc=100\",\n",
    "        # \"new_apartments\": \"https://suumo.jp/jj/bukken/ichiran/JJ011FC001/?ar=030&bs=010&ta=13&po=0&pj=1&initFlg=1&bknlistmodeflg=1&page=1&pc=100\",\n",
    "        \"used_houses\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=021&cn=9999999&cnb=0&ekTjCd=&ekTjNm=&hb=0&ht=9999999&kb=1&kt=9999999&sc=13101&sc=13102&sc=13103&sc=13104&sc=13105&sc=13113&sc=13106&sc=13107&sc=13108&sc=13118&sc=13121&sc=13122&sc=13123&sc=13109&sc=13110&sc=13111&sc=13112&sc=13114&sc=13115&sc=13120&sc=13116&sc=13117&sc=13119&ta=13&tb=0&tj=0&tt=9999999&po=0&pj=1&pc=100\",\n",
    "        # \"new_houses\": \"https://suumo.jp/jj/bukken/ichiran/JJ012FC001/?ar=030&bs=020&ekTjCd=&ekTjNm=&hb=0&ht=9999999&kb=1&km=1&kt=9999999&kw=1&sc=13102&sc=13103&sc=13104&sc=13105&sc=13113&sc=13106&sc=13107&sc=13108&sc=13118&sc=13121&sc=13122&sc=13123&sc=13109&sc=13110&sc=13111&sc=13112&sc=13114&sc=13115&sc=13120&sc=13116&sc=13117&sc=13119&ta=13&tb=0&tj=0&tt=9999999&po=0&pj=1&pc=100\"\n",
    "    }\n",
    "\n",
    "    list_urls = []\n",
    "    page = 0\n",
    "\n",
    "    for category, url in collection_pages.items():\n",
    "        print(f\"Category: {category}\")\n",
    "\n",
    "        while True:\n",
    "            soup = get_html(url.format(page))\n",
    "            \n",
    "            if not soup:\n",
    "                print(f\"No soup in {url}\")\n",
    "                break \n",
    "\n",
    "            for h2 in soup.find_all('h2', class_='property_unit-title'):\n",
    "                a_tag = h2.find('a', href=True) \n",
    "                if a_tag and a_tag['href']:\n",
    "                    property_url = \"https://suumo.jp\" + a_tag['href']\n",
    "                    list_urls.append((category, property_url))\n",
    "\n",
    "            # Find the 'next' page link with text \"次へ\"\n",
    "            next_page = soup.find('a', text=\"次へ\")\n",
    "            if next_page and next_page.get('href'):\n",
    "                url = \"https://suumo.jp\" + next_page['href']\n",
    "            else:\n",
    "                print(f\"No more {category} pages.\")\n",
    "                break\n",
    "\n",
    "    df_urls = pd.DataFrame(list_urls, columns=['Category', 'URL'])\n",
    "    df_urls.to_csv(\"/app/data/property_urls.csv\", index=False)\n",
    "    df_urls.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a65362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. URL: https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_75070928/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'price': 11900000,\n",
       " 'plan': '2DK',\n",
       " 'area': 41.34,\n",
       " 'level': 2,\n",
       " 'no_floors': 4,\n",
       " 'year': 1979,\n",
       " 'address': '東京都足立区花畑５-2-9'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "price:          価格                           headerKakakuDisp : [\"11900000\"],\n",
    "area:           専有面積                        senyuMensekiDisp : [\"41.34\"]\n",
    "level:          所在階/構造・階建   BEFORE /\n",
    "no_floors:      所在階/構造・階建   AFTER /\n",
    "plan:           間取り                          madoriDisp : [\"2DK\"]\n",
    "year:           完成時期（築年月）  BEFORE 年     kanseiDateDisp : \"197911\"\n",
    "address:        住所\n",
    "building-type:                                 ryoikiShuNm : '中古マンション'\n",
    "\n",
    "\n",
    "area                            0.201484    area\n",
    "building_type_apartment         0.064314    building_type_apartment\n",
    "year                            0.036422    year\n",
    "is_furnished_with_appliances    0.034590\n",
    "has_delivery_box                0.031909\n",
    "latitude                        0.031609    latitude\n",
    "no_rooms                        0.027744    \n",
    "longitude                       0.022122    longitude\n",
    "no_floors                       0.021162    no_floors\n",
    "layout_2LDK                     0.020122    l\n",
    "has_system_kitchen              0.019310\n",
    "layout_1LDK                     0.019068    l\n",
    "layout_3K                       0.018329    l\n",
    "has_private_garden              0.016308\n",
    "layout_4K                       0.016281    l\n",
    "layout_4DK                      0.014993    l\n",
    "is_instrument_ok                0.014724\n",
    "has_basement                    0.014499\n",
    "is_office_use_allowed           0.012668\n",
    "has_bathroom_dryer              0.012218\n",
    "has_soundproof_room             0.011944\n",
    "building_type_mansion           0.011404    building_type_mansion\n",
    "has_elevator                    0.011175\n",
    "is_tower_mansion                0.010824\n",
    "is_pet_allowed                  0.010696\n",
    "\"\"\"\n",
    "\n",
    "# def clean_text(text):\n",
    "#     return text.strip().split('（')[0].strip()\n",
    "#     # return text #' '.join(text.split())\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_number(string):\n",
    "    match = re.search(r'\\d+', string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "pd_urls = pd.read_csv(\"/app/data/property_urls.csv\", index_col=False)\n",
    "df_urls = pd.DataFrame(pd_urls, columns=['Category', 'URL'])\n",
    "df_urls.head()\n",
    "\n",
    "list_data = []\n",
    "\n",
    "count = 0\n",
    "total = len(df_urls)\n",
    "batch_size = 1000\n",
    "\n",
    "for url in df_urls['URL']:\n",
    "    print(f\"1. URL: {url}\")\n",
    "    soup = get_html(url)\n",
    "\n",
    "    if not soup:\n",
    "        print(f\"No soup in {url}\")\n",
    "        break \n",
    "\n",
    "    # Initialize dictionary to store the data\n",
    "    property_data = {}\n",
    "\n",
    "    # Iterate over each row in the table\n",
    "    target_table = soup.find('table', summary=\"表\")\n",
    "    for row in target_table.find_all('tr'):\n",
    "        # Find all th and td pairs in the row\n",
    "        ths = row.find_all('th')\n",
    "        tds = row.find_all('td')\n",
    "        \n",
    "        for th, td in zip(ths, tds):\n",
    "            header = th.text.strip()\n",
    "            value = td.text.strip()\n",
    "\n",
    "            if \"価格\" in header:\n",
    "                str_price = clean_text(value).split('円')[0]\n",
    "                if str_price[-1] == '万':\n",
    "                    property_data['price'] = int(str_price.replace('万', '')) * 10000\n",
    "                else:\n",
    "                    property_data['price'] = int(str_price)\n",
    "            elif \"間取り\" in header:\n",
    "                # print(f\"1. {clean_text(value)}\")\n",
    "                property_data['plan'] = clean_text(value)\n",
    "            elif \"専有面積\" in header:\n",
    "                property_data['area'] = float(clean_text(value).split('m2')[0])\n",
    "            elif \"所在階/構造・階建\" in header:\n",
    "                level_details = clean_text(value).split('/')\n",
    "                property_data['level'] = extract_number(level_details[0])\n",
    "                property_data['no_floors'] = extract_number(level_details[1])\n",
    "            elif \"完成時期（築年月）\" in header:\n",
    "                # print(f\"2. {clean_text(value)}\")\n",
    "                property_data['year'] = int(clean_text(value).split('年')[0])\n",
    "            elif \"住所\" in header:\n",
    "                property_data['address'] = clean_text(value).split('\\n')[0]\n",
    "\n",
    "    \n",
    "    # scripts = soup.find_all('script')\n",
    "    # for script in scripts:\n",
    "    #     # print(f\"2. script: {script}\")\n",
    "    #     if 'gapSuumoPcForKr' in script.text:\n",
    "            \n",
    "    #         # Extract the JSON-like object\n",
    "    #         matches = re.search(r'var gapSuumoPcForKr = (\\[.*?\\]);', script.text, re.DOTALL)\n",
    "    #         if matches:\n",
    "    #             json_like = matches.group(1)\n",
    "\n",
    "    #             # Remove the JavaScript variable declaration\n",
    "    #             json_string = re.sub(r'^var\\s+\\w+\\s*=\\s*', '', json_like.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    #             # Remove single and multi-line comments\n",
    "    #             json_string = re.sub(r'//.*?$|/\\*.*?\\*/', '', json_string, flags=re.MULTILINE | re.DOTALL)\n",
    "\n",
    "    #             # Ensure all keys and string values are in double quotes\n",
    "    #             json_string = re.sub(r'(\\w+)\\s*:', r'\"\\1\":', json_string)  # Quote keys\n",
    "    #             json_string = re.sub(r':\\s*([^\"{\\d\\[\\]}\\s].*?)(,|\\])', r': \"\\1\"\\2', json_string)  # Quote non-quoted values\n",
    "\n",
    "    #             # Handling trailing comma if any before closing brackets\n",
    "    #             json_string = re.sub(r',\\s*([\\]}])', r'\\1', json_string)\n",
    "\n",
    "    #             # Convert to Python dictionary\n",
    "    #             data = json.loads(json_string)\n",
    "\n",
    "    #             if data['madoriDisp'][0]:\n",
    "    #                 property_data['plan'] = clean_text(data['madoriDisp'][0])\n",
    "    #             if data['kanseiDateDisp']:\n",
    "    #                 property_data['year'] = int(data['kanseiDateDisp'][:4])\n",
    "    #             if data['headerKakakuDisp']:\n",
    "    #                 property_data['price'] = int(data['headerKakakuDisp'][0])\n",
    "\n",
    "    break\n",
    "property_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_property_data(url):\n",
    "    \n",
    "\n",
    "# pd_urls = pd.read_csv(\"/app/data/property_urls.csv\", index_col=False)\n",
    "# df_urls = pd.DataFrame(pd_urls, columns=['Category', 'URL'])\n",
    "# df_urls.head()\n",
    "\n",
    "# property_data = []\n",
    "\n",
    "# count = 0\n",
    "# total = len(df_urls)\n",
    "# batch_size = 1000\n",
    "\n",
    "# for url in df_urls['URL']:\n",
    "#     soup = get_html(url)\n",
    "\n",
    "#     if not soup:\n",
    "#         print(f\"No soup in {url}\")\n",
    "#         property_data.append({'URL': url, \n",
    "#                         '向き': \"掲載終了\", \n",
    "#                         '間取り詳細': \"掲載終了\", \n",
    "#                         '物件の構造': \"掲載終了\", \n",
    "#                         '物件の階建': \"掲載終了\",\n",
    "#                         '築年月': \"掲載終了\", \n",
    "#                         '損保': \"掲載終了\", \n",
    "#                         '駐車場': \"掲載終了\", \n",
    "#                         '取引態様': \"掲載終了\",\n",
    "#                         '条件': \"掲載終了\", \n",
    "#                         '総戸数': \"掲載終了\", \n",
    "#                         '契約期間': \"掲載終了\", \n",
    "#                         '仲介手数料': \"掲載終了\",\n",
    "#                         '保証会社': \"掲載終了\", \n",
    "#                         '備考': \"掲載終了\", \n",
    "#                         '部屋の特徴': \"掲載終了\"})\n",
    "#         break \n",
    "\n",
    "#     # Find the \"Direction\"\n",
    "#     try:\n",
    "#         element = soup.find(\"table\", {\"class\": \"property_view_table\"})\n",
    "#         direction = element.find('th', string=\"向き\").find_next_sibling('td').get_text(strip=True)\n",
    "#     except AttributeError:\n",
    "#         direction = 'Null'\n",
    "    \n",
    "#     # Find the required data table\n",
    "#     tbodys = soup.find(\"table\", {\"class\": \"data_table table_gaiyou\"})\n",
    "    \n",
    "#     # Define a function to safely fetch the data for each field\n",
    "#     def get_text_safe(th_string):\n",
    "#         try:\n",
    "#             return tbodys.find('th', string=th_string).find_next_sibling('td').get_text(strip=True)\n",
    "#         except AttributeError:\n",
    "#             return 'Null'\n",
    "    \n",
    "#     # Use the function to fetch data for each field\n",
    "#     layout_detail = get_text_safe('間取り詳細')\n",
    "#     structure = get_text_safe('構造')\n",
    "#     floor = get_text_safe('階建')\n",
    "#     yearmonth = get_text_safe('築年月')\n",
    "#     insurance = get_text_safe('損保')\n",
    "#     parking = get_text_safe('駐車場')\n",
    "#     transaction_type = get_text_safe('取引態様')\n",
    "#     conditions = get_text_safe('条件')\n",
    "#     total_units = get_text_safe('総戸数')\n",
    "#     lease_term = get_text_safe('契約期間')\n",
    "#     intermediary_fee = get_text_safe('仲介手数料')\n",
    "#     guarantee_company = get_text_safe('保証会社')\n",
    "#     note = get_text_safe('備考')\n",
    "\n",
    "#     # Find room features\n",
    "#     try:\n",
    "#         li_element = soup.find('div', {'id': 'bkdt-option'}).find('li')\n",
    "#         feature = li_element.get_text(strip=True)\n",
    "#     except AttributeError:\n",
    "#         feature = 'Null'\n",
    "\n",
    "#     # Append the data to the list\n",
    "#     property_data.append({\n",
    "#         'URL': url,\n",
    "#         '向き': direction,\n",
    "#         '間取り詳細': layout_detail,\n",
    "#         '物件の構造': structure,\n",
    "#         '物件の階建': floor,\n",
    "#         '築年月': yearmonth,\n",
    "#         '損保': insurance,\n",
    "#         '駐車場': parking,\n",
    "#         '取引態様': transaction_type,\n",
    "#         '条件': conditions,\n",
    "#         '総戸数': total_units,\n",
    "#         '契約期間': lease_term,\n",
    "#         '仲介手数料': intermediary_fee,\n",
    "#         '保証会社': guarantee_company,\n",
    "#         '備考': note,\n",
    "#         '部屋の特徴': feature\n",
    "#     })\n",
    "    \n",
    "#     # Update the counter and print the current progress\n",
    "#     count += 1\n",
    "#     print(f\"Processed {count}/{total} URLs\")\n",
    "\n",
    "#     # Periodically save property_data and clear the list from memory\n",
    "#     if count % batch_size == 0:\n",
    "#         partial_df = pd.DataFrame(property_data)\n",
    "#         partial_df.to_csv(f'property_data_part_{count // batch_size}.csv', index=False)\n",
    "#         property_data.clear()\n",
    "#         gc.collect()  # Manually release memory\n",
    "#         time.sleep(5)  # Rest 5 seconds to reduce server load\n",
    "#     partial_df = pd.DataFrame(property_data)\n",
    "#     partial_df.head()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce383fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>向き</th>\n",
       "      <th>間取り詳細</th>\n",
       "      <th>物件の構造</th>\n",
       "      <th>物件の階建</th>\n",
       "      <th>築年月</th>\n",
       "      <th>損保</th>\n",
       "      <th>駐車場</th>\n",
       "      <th>取引態様</th>\n",
       "      <th>条件</th>\n",
       "      <th>総戸数</th>\n",
       "      <th>契約期間</th>\n",
       "      <th>仲介手数料</th>\n",
       "      <th>保証会社</th>\n",
       "      <th>備考</th>\n",
       "      <th>部屋の特徴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL    向き 間取り詳細 物件の構造 物件の階建  \\\n",
       "0  https://suumo.jp/ms/chuko/tokyo/sc_adachi/nc_7...  Null  Null  Null  Null   \n",
       "\n",
       "    築年月    損保   駐車場  取引態様    条件   総戸数  契約期間 仲介手数料  保証会社    備考 部屋の特徴  \n",
       "0  Null  Null  Null  Null  Null  Null  Null  Null  Null  Null  Null  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b2819-d8b7-4728-957e-fe1a4cde0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for page in range(1, max_page + 1):\n",
    "#     url = base_url.format(page) # Replace {} with page number\n",
    "#     soup = get_html(url)        # Get parsed data\n",
    "\n",
    "#     property_tags = soup.findAll(\"div\", {\"class\": \"cassetteitem\"})  # All <div>'s with \"cassetteitem\" in the class attribute contain propetry info.\n",
    "    \n",
    "#     # print(f\"Page: {page} - items: {property_tags}\")\n",
    "    \n",
    "#     for property_tag in property_tags:\n",
    "#         stations = property_tag.findAll(\"div\", {\"class\": \"cassetteitem_detail-text\"})\n",
    "        \n",
    "#         # process each station\n",
    "#         for station in stations:\n",
    "#             # define variable \n",
    "#             base_data = {}\n",
    "\n",
    "#             # collect base information    \n",
    "#             # Name\n",
    "#             base_data[\"名称\"] = property_tag.find(\"div\", {\"class\": \"cassetteitem_content-title\"}).getText().strip()\n",
    "            \n",
    "#             # category\n",
    "#             base_data[\"カテゴリー\"] = property_tag.find(\"div\", {\"class\": \"cassetteitem_content-label\"}).getText().strip()\n",
    "\n",
    "#             # address\n",
    "#             base_data[\"アドレス\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col1\"}).getText().strip()\n",
    "\n",
    "#             # nearby station\n",
    "#             base_data[\"アクセス\"] = station.getText().strip()\n",
    "\n",
    "#             # building's age\n",
    "#             base_data[\"築年数\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col3\"}).findAll(\"div\")[0].getText().strip()\n",
    "\n",
    "#             # structure\n",
    "#             base_data[\"構造\"] = property_tag.find(\"li\", {\"class\": \"cassetteitem_detail-col3\"}).findAll(\"div\")[1].getText().strip()\n",
    "            \n",
    "#             # process data for each room\n",
    "#             tbodys = property_tag.find(\"table\", {\"class\": \"cassetteitem_other\"}).findAll(\"tbody\")\n",
    "            \n",
    "#             for tbody in tbodys:\n",
    "#                 data = base_data.copy()\n",
    "\n",
    "#                 # floor\n",
    "#                 data[\"階数\"] = tbody.findAll(\"td\")[2].getText().strip()\n",
    "\n",
    "#                 # rent\n",
    "#                 data[\"家賃\"] = tbody.findAll(\"td\")[3].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 # Management fee\n",
    "#                 data[\"管理費\"] = tbody.findAll(\"td\")[3].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 # deposit\n",
    "#                 data[\"敷金\"] = tbody.findAll(\"td\")[4].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 #gratuity fee\n",
    "#                 data[\"礼金\"] = tbody.findAll(\"td\")[4].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 #layout\n",
    "#                 data[\"間取り\"] = tbody.findAll(\"td\")[5].findAll(\"li\")[0].getText().strip()\n",
    "\n",
    "#                 #area(m^2)\n",
    "#                 data[\"面積\"] = tbody.findAll(\"td\")[5].findAll(\"li\")[1].getText().strip()\n",
    "\n",
    "#                 data[\"URL\"] = \"https://suumo.jp\" + tbody.findAll(\"td\")[8].find(\"a\").get(\"href\")\n",
    "                \n",
    "#                 all_data.append(data)\n",
    "# df = pd.DataFrame(all_data)\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
